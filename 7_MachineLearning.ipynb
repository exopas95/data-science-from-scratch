{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기계학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 모델링\n",
    "기계 학습에 대해 얘기하기 전에 __모델(model)__ 이 무엇인지 먼저 살펴보자.\n",
    "- 모델: 다양한 변수 간의 수학적 혹은 확률적 관계를 표현한 것\n",
    "\n",
    "예를 들어 소셜 네트워킹 사이트를 통해 수익을 창출하고자 할 때, '사용자의 수'나 '사용자당 광고 수익', 혹은 '직원 수'같은 입력 변수로 차후 몇 년 동안의 연간 수익을 예측하는 비즈니스 모델을 만들곤 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 기계학습이란?\n",
    "이 책에서 정의하는 기계학습의 정의는 다음과 같다.\n",
    "- 데이터를 통해 모델을 만들고 사용하는 것\n",
    "\n",
    "다른 맥락에서 이는 예측 모델링(predictive modeling) 혹은 데이터마이닝(data mining)이라 불릴 수도 있지만 일단 이책에서는 그러한 과정을 기게학습이라 부르기로 한다. <br>\n",
    "\n",
    "모델의 종류는 크게 네 가지로 나눈다.\n",
    "- 지도 학습(Supervised Learning): 학습에 사용될 데이터에 정담이 포함됨\n",
    "- 비지도 학습(Unsupervised Learning): 학습에 사용될 데이터에 정담이 포함되어 있지 않음\n",
    "- 준 지도 학습(Semi-Supervised Learning): 데이터의 일부에만 정답이 포함되어 있음\n",
    "- 온라인 학습(Online Learning): 새로 들어오는 데이터를 통해 모델을 끊임없이 조정함\n",
    "- 강화 학습(Reinforement Learning): 연속된 예측 뒤 모델이 얼마나 잘 예측했는지를 파악함\n",
    "\n",
    "여러가지 모델이 존재하지만 일반적으로 파라미터가 있는 파라메트릭(parametric) 모델을 고른 후, 데이터를 통해 파라미터의 최적값을 찾으려고 한다는 공통점을 가지고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 오버피팅과 언더피팅\n",
    "기계학습의 일반적인 문제점으로 오버피팅과 언더피팅이 있다.\n",
    "- 오버피팅: 만들어진 모델의 성능이 학습 데이터에서는 좋지만, 기존에 관측한 적이 없는 새로운 데이터에서는 좋지 않은 경우를 의미\n",
    "- 언더피팅: 모델의 성능이 학습 데이터에서도 좋지 않은 경우를 의미\n",
    "\n",
    "모델이 너무 복잡하면 오버피팅이 발생하며, 학습 데이터 이외의 데이터에서는 일반적으로 적용할 수 없다는 것을 알 수 있다. 그렇다면 복잡하지 않은 모델을 어떻게 만들 수 있을까? 이를 해결하는 가장 쉬운 방법은 각각 다른 데이터로 모델을 학습시키고 평가하는 것이다. 만일 모델의 학습 데이터에 오버피팅됐다면 평가 데이터에서 모델의 성능은 좋지 않을 것이다. 하지만 이 경우, 더 큰 데이터에는 존재하지 않을 패턴이 학습 데이터와 평가 데이터에 공통적으로 존재할 수 있다는 문제점이 있다. <br>\n",
    "\n",
    "더 큰 문제는 학습 데이터와 평가 데이터로 하나의 모델을 평가할 때가 아니라 여러 모델 중에서 하나의 모델을 선택할 때 발생한다. 이 경우 각각의 모델은 오버피팅되지 않겠지만, 평가 데이터에서 성능이 제일 좋은 모델을 선택한다면 이는 평가 데이터를 일종의 두 번째 학습 데이터로 사용하는 메타 학습의 문제가 발생한다. 당연히 평가 데이터에서 성능이 제일 좋았던 모델을 동일한 평가 데이터로 평가한다면 좋은 성능이 나올 수 밖에 없다. 이러한 경우 데이터를 세 종류로 나눠서 학습데이터로 모델을 만들고 __검증 데이터(Validation set)__ 를 통해 학습된 여러 모델 중 하나를 선택고, 평가 데이터로 최종 모델의 성능을 평가할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 정확도(Accuracy)\n",
    "모델을 평가하기 위해서, 특히 이진 분류 모델을 평가하기 위해서 보통 정확도를 쓰지 않는다. 가령 이진 분류 모델을 만든다고 했을 때 모든 데이터는 다음 네 가지 분류 중 하나에 속하게 된다.\n",
    "- True Positive(TP, 진양성): 실제로 스팸 메일이며 정확하게 스팸으로 분류\n",
    "- Flase Positive(FP, 가양성): 스팸 메일이 아니지만 스팸으로 분류\n",
    "- False Negative(FN, 가음성): 스팸 메일이지만 스팸이 아닌 것으로 분류\n",
    "- True Negative(TN, 진음성): 스팸 메일이 아니며 스팸이 아닌 것으로 분류\n",
    "\n",
    "이러한 정보는 혼동행렬(Confusion Matrix)을 사용해서 표현한다. \n",
    "\n",
    "|                                |실제로 스팸 메일인 경우    |실제로 스팸 메일이 아닌 경우   |\n",
    "|:-------------------------------|:--------------------------|:------------------------------|\n",
    "|스팸 메일로 분류                |True positive              |False positive                 |\n",
    "|스팸 메일이 아닌 것으로 분류    |False negative             |True negative                  |\n",
    "\n",
    "이때 정확도는 TP / (TP + TN)으로 FP와 FN에 영향을 받지 않기 때문에 정확하지 않다. 예를 들어 TP가 70이고 FP가 1000, TN이 0인 경우, 정확도는 100%이다. 하지만 실제로 스팸 메일이 아닌데도 스팸 메일로 분류한 것의 비율이 압도적으로 많기 때문에 모델의 성능이 좋다고 평가할 수 없다. 이와 같은 일을 방지하기 위하여 정밀도와 재현율 그리고 두 수치를 합친 F1 점수로 모델을 평가한다.\n",
    "- 정밀도(Precision): 양성으로 예측된 결과의 정확도 -> TP / (TP + FP)\n",
    "- 재현율(Recall): 실제 양성 중 모델이 정확하게 양성으로 예측한 비율 -> TP / (TP + FN)\n",
    "- F1 Score: 정밀도와 재현율의 조화 평균 -> 2 * Precision * Recall / (Precision + Recall)\n",
    "\n",
    "이때 F1 Score에서 조화 평균을 사용한 이유는 precision 혹은 recall이 0에 가까울 때 F1 Score도 0에 가깝게 하기 위해서이다. 예를 들어 recall = 1이고 precision = 0.01인 모델이 있다고 가정하자. precision의 수치가 매우 낮기 때문에 좋은 모델이 아님에도 두 수치의 산술 평균을 계산하면 0.505 라는 높은 점수를 얻게 된다. 하지만 조화 평균을 이용하면 0.019라는 낮은 수치를 얻게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bias-Variance Trade off\n",
    "오버피팅의 문제는 bias(편향)와 variance(분산)의 trade off라고 볼 수 있다. 두 수치는 모두 모델을 더 큰 모집단에서 추출한 다양한 학습 데이터로 다시 학습시키면 어떠한 변화가 발생하는지 설명해 준다.\n",
    "- 오버피팅: 편향이 작고 분산이 큰 경우\n",
    "- 언더피팅: 편향이 크고 분산이 작은 경우\n",
    "\n",
    "분산과 편향의 문제를 해결하기 위한 해결책은 다음과 같다.\n",
    "- 편향이 매우 큰 경우: 새로운 변수를 추가\n",
    "- 분산이 매우 큰 경우: 모델의 변수를 줄이거나 더 많은 데이터를 구해서 모델을 학습시킴"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
